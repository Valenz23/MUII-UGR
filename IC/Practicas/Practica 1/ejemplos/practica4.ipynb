{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 4. Redes Convolucionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.utils' has no attribute 'to_categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\gDrive\\pvalenzuela\\Mi unidad\\Master\\IC\\Practicas\\ejemplos red\\practica4.ipynb Celda 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m x_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(x_test, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# convert class vectors to binary class matrices\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m y_train \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mto_categorical(y_train, num_classes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m y_test \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_test, num_classes)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.utils' has no attribute 'to_categorical'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "num_classes = 10                # numeros [0-9]\n",
    "input_shape = (28, 28, 1)       \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal Convolucional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"redensia\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = keras.Sequential(   \n",
    "#     [\n",
    "#         keras.Input(shape=input_shape),         \n",
    "#         layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_classes, activation=\"softmax\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# otro constructor por capas (add/pop)\n",
    "model = keras.Sequential(name=\"redensia\")\n",
    "\n",
    "#capas\n",
    "model.add(keras.Input(shape=input_shape))                               # entrada -> dimensiones\n",
    "model.add(layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\"))      # filtro 2D, normalmente se usan kernels 2x2/3x3, tamaño 32/64\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))                            # draw-sampling, agrupa para reducir dimensionalidad\n",
    "model.add(layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"))      # otro filtro\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))                            # ms agrupacion\n",
    "model.add(layers.Flatten())                                             # reduce a un vector\n",
    "model.add(layers.Dropout(0.5))                                          # porcentaje de neuronas que se apagan durante el aprendizaje, evita sobreaprendizaje\n",
    "model.add(layers.Dense(num_classes, activation=\"softmax\"))              # capa, en este caso es la salida tambien\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\gDrive\\pvalenzuela\\Mi unidad\\Master\\IC\\Practicas\\ejemplos red\\practica4.ipynb Celda 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,    \u001b[39m# funcion de perdida\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m,                   \u001b[39m# de optimizacion\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]                \u001b[39m# metrica\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x_train,                        \u001b[39m# conjunto de entrenamiento\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     y_train,                        \u001b[39m# de test\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,          \u001b[39m# tamaño lotes\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,                  \u001b[39m# epocas (repeticiones)\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m            \u001b[39m# controla el sobreaprendizaje\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1137\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m cluster_coordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[0;32m   1132\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy)\n\u001b[0;32m   1134\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), \\\n\u001b[0;32m   1135\u001b[0m      training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1136\u001b[0m   \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m   data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   1138\u001b[0m       x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   1139\u001b[0m       y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   1140\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1141\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1142\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1143\u001b[0m       initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   1144\u001b[0m       epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1145\u001b[0m       shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1146\u001b[0m       class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1147\u001b[0m       max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1148\u001b[0m       workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1149\u001b[0m       use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1150\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1151\u001b[0m       steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[0;32m   1153\u001b[0m   \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1397\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1396\u001b[0m   \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1397\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1151\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1148\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1149\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_value \u001b[39m=\u001b[39m steps_per_execution\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m-> 1151\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m   1152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1153\u001b[0m     x,\n\u001b[0;32m   1154\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1163\u001b[0m     distribution_strategy\u001b[39m=\u001b[39mdistribute_lib\u001b[39m.\u001b[39mget_strategy(),\n\u001b[0;32m   1164\u001b[0m     model\u001b[39m=\u001b[39mmodel)\n\u001b[0;32m   1166\u001b[0m strategy \u001b[39m=\u001b[39m distribute_lib\u001b[39m.\u001b[39mget_strategy()\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:987\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    986\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m   adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    988\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    989\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:987\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    986\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m   adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcan_handle(x, y)]\n\u001b[0;32m    988\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    989\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:706\u001b[0m, in \u001b[0;36mDatasetAdapter.can_handle\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcan_handle\u001b[39m(x, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    705\u001b[0m   \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(x, (data_types\u001b[39m.\u001b[39mDatasetV1, data_types\u001b[39m.\u001b[39mDatasetV2)) \u001b[39mor\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m           _is_distributed_dataset(x))\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1696\u001b[0m, in \u001b[0;36m_is_distributed_dataset\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_distributed_dataset\u001b[39m(ds):\n\u001b[1;32m-> 1696\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(ds, input_lib\u001b[39m.\u001b[39;49mDistributedDatasetInterface)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",    # funcion de perdida\n",
    "    optimizer=\"adam\",                   # de optimizacion\n",
    "    metrics=[\"accuracy\"]                # metrica\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,                        # conjunto de entrenamiento\n",
    "    y_train,                        # de test\n",
    "    batch_size=batch_size,          # tamaño lotes\n",
    "    epochs=epochs,                  # epocas (repeticiones)\n",
    "    validation_split=0.1            # controla el sobreaprendizaje\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.030098559334874153\n",
      "Test accuracy: 0.989300012588501\n",
      "Test error rate: 1.0699987411499023\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "print(\"Test error rate:\", (1 - score[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiper-parámetros con Keras-Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x214b9403790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers\n",
    "import keras_tuner\n",
    "\n",
    "# funcion que contruye una red convolucional\n",
    "def call_existing_code(units, activation, dropout, lr):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=units, activation=activation))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# contruye el modelo con varios parametros\n",
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = call_existing_code(\n",
    "        units=units, activation=activation, dropout=dropout, lr=lr\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras' has no attribute 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\gDrive\\pvalenzuela\\Mi unidad\\Master\\IC\\Practicas\\ejemplos red\\practica4.ipynb Celda 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (x, y), (x_test, y_test) \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39mmnist\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x_train \u001b[39m=\u001b[39m x[:\u001b[39m-\u001b[39m\u001b[39m10000\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/ejemplos%20red/practica4.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x_val \u001b[39m=\u001b[39m x[\u001b[39m-\u001b[39m\u001b[39m10000\u001b[39m:]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.keras' has no attribute 'datasets'"
     ]
    }
   ],
   "source": [
    "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x[:-10000]\n",
    "x_val = x[-10000:]\n",
    "y_train = y[:-10000]\n",
    "y_val = y[-10000:]\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# usa las funciones antes definidas\n",
    "# prueba en todas las configuraciones, como GridSearch\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " module_wrapper (ModuleWrap  (None, 784)               0         \n",
      " per)                                                            \n",
      "                                                                 \n",
      " module_wrapper_1 (ModuleWr  (None, 512)               401920    \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_2 (ModuleWr  (None, 512)               0         \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_3 (ModuleWr  (None, 10)                5130      \n",
      " apper)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 28, 28))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0005653899495964376\n",
      "Score: 0.972100019454956\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "activation: tanh\n",
      "dropout: True\n",
      "lr: 0.0006361349306744992\n",
      "Score: 0.9543000161647797\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "activation: tanh\n",
      "dropout: True\n",
      "lr: 0.00018840040300474622\n",
      "Score: 0.9294500052928925\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-entranando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2578 - accuracy: 0.9268\n",
      "Test loss: 0.12047871947288513\n",
      "Test accuracy: 0.9634000062942505\n",
      "Test error rate: 3.659999370574951\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((x_train, x_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "model.fit(x=x_all, y=y_all, epochs=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "print(\"Test error rate:\", (1 - score[1])*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0.0963003896176815,\n",
       " 'max': 0.0963003896176815,\n",
       " 'mean': 0.0963003896176815,\n",
       " 'median': 0.0963003896176815,\n",
       " 'var': 0.0,\n",
       " 'std': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.oracle.trials['0'].metrics.metrics['val_loss'].get_statistics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de parámetros con apoyo de Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'class_weight'])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\gDrive\\pvalenzuela\\Mi unidad\\Master\\IC\\Practicas\\Practica 1\\ejemplos\\practica4.ipynb Celda 16\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m cv \u001b[39m=\u001b[39m RepeatedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m                       param_grid\u001b[39m=\u001b[39mparam_grid, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m                       scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m                       cv\u001b[39m=\u001b[39mcv, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m                       n_jobs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m grid_result \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mx_train, y\u001b[39m=\u001b[39;49my_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# ahora llevar a pandas y funciones estadisiticas de practica 3\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m# esto tarda muncho por las epocas y por que no hay early stopping\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gDrive/pvalenzuela/Mi%20unidad/Master/IC/Practicas/Practica%201/ejemplos/practica4.ipynb#X21sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m# del predict --> hacer un script quitando todo lo que no sea un numero: CONSEGUIR SUPERNUMERO\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.python.keras import layers\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "import numpy as np\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x[:-10000]\n",
    "x_val = x[-10000:]\n",
    "y_train = y[:-10000]\n",
    "y_val = y[-10000:]\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(kernel_size=(2,2), pool_size=(2,2), rate=0.5):\n",
    "    # create model\n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=kernel_size, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=pool_size),\n",
    "        layers.Conv2D(64, kernel_size=kernel_size, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=pool_size),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(rate=rate),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "    # Compile model\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    " \n",
    "# fix random seed for reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "print(model.get_params().keys())\n",
    "\n",
    "kernel_sizes = [(2,2), (3,3)]\n",
    "pool_sizes = [(2,2)]\n",
    "rates = [0.5, 0.75]\n",
    "\n",
    "epochs = [50]\n",
    "batches = [128]\n",
    "\n",
    "param_grid = dict(model__kernel_size=kernel_sizes,  ##model__JUAN por parametros raros nose\n",
    "                  epochs=epochs, \n",
    "                  batch_size=batches, \n",
    "                  model__pool_size=pool_sizes,\n",
    "                  model__rate=rates)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=3, n_repeats=2, random_state=123)\n",
    "\n",
    "search = GridSearchCV(estimator=model, \n",
    "                      param_grid=param_grid, \n",
    "                      scoring=\"accuracy\", \n",
    "                      cv=cv, \n",
    "                      n_jobs=10)\n",
    "\n",
    "grid_result = search.fit(X=x_train, y=y_train)\n",
    "\n",
    "# ahora llevar a pandas y funciones estadisiticas de practica 3\n",
    "# esto tarda muncho por las epocas y por que no hay early stopping\n",
    "\n",
    "# jogar ---\n",
    "# kernel de 3x3 dpm\n",
    "# lotes 128, 256, 512\n",
    "# learning rate 0.001\n",
    "\n",
    "# del predict --> hacer un script quitando todo lo que no sea un numero: CONSEGUIR SUPERNUMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpraci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
